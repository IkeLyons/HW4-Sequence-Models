{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SequenceModels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1OweUI7F-7t3q_iNUKTw-kl71GazFLMXK",
      "authorship_tag": "ABX9TyOpjo5hKZcJX6L1v7JB3r8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IkeLyons/HW4-Sequence-Models/blob/main/SequenceModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQkC_Q6KLzn_"
      },
      "source": [
        "In this homework I am going to try to generate text based off of the script of Star Wars (dataset link: https://www.kaggle.com/xvivancos/star-wars-movie-scripts). DESCRIBE HERE WHY THIS NEEDS TO BE SOLVED USING SEQUENCE MODELS!!!!!!!!!!!!!!!!! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wAMevRY00TE",
        "outputId": "4beec708-8307-4e19-eab2-19fecb2b7b5d"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkuUcgnw5XZj"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjcdXgvz5ZXe"
      },
      "source": [
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMnM1vqv5cme",
        "outputId": "69b6f3d4-5b4b-4e22-98b6-a42dbf674879"
      },
      "source": [
        "! kaggle datasets download xvivancos/star-wars-movie-scripts"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading star-wars-movie-scripts.zip to /content\n",
            "\r  0% 0.00/158k [00:00<?, ?B/s]\n",
            "\r100% 158k/158k [00:00<00:00, 62.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmP-OVB45nJB",
        "outputId": "86faec94-bdf9-45c5-fef4-2d2c9f9eaf70"
      },
      "source": [
        "! unzip star-wars-movie-scripts.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  star-wars-movie-scripts.zip\n",
            "  inflating: SW_EpisodeIV.txt        \n",
            "  inflating: SW_EpisodeV.txt         \n",
            "  inflating: SW_EpisodeVI.txt        \n",
            "  inflating: wordcloud_masks/r2d2.png  \n",
            "  inflating: wordcloud_masks/rebel alliance.png  \n",
            "  inflating: wordcloud_masks/vader.png  \n",
            "  inflating: wordcloud_masks/yoda.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cd4zXQ5NP95"
      },
      "source": [
        "We are using TensorFlow and some of the Keras utilties in order to solve this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-hU5EC1NOWR"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGbRUsBINW7Y",
        "outputId": "cc53ae00-dea7-4f81-db1c-0d159e30a623"
      },
      "source": [
        "text = open('SW_EpisodeIV.txt', 'rb').read().decode(encoding='utf-8')\n",
        "text = text.lower()\n",
        "text = text.replace('\"', '')\n",
        "print(text[:500])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "character dialogue\n",
            "1 threepio did you hear that?  they've shut down the main reactor.  we'll be destroyed for sure.  this is madness!\n",
            "2 threepio we're doomed!\n",
            "3 threepio there'll be no escape for the princess this time.\n",
            "4 threepio what's that?\n",
            "5 threepio i should have known better than to trust the logic of a half-sized thermocapsulary dehousing assister...\n",
            "6 luke hurry up!  come with me!  what are you waiting for?!  get in gear!\n",
            "7 threepio artoo! artoo-detoo, where are you?\n",
            "8 threepio at last! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgMEEFTDOPLS"
      },
      "source": [
        "We can see that the script has 3 main parts: the line number, the character speaking, and what the character said. It will be interesting to see how the models are able to recreate this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CixuJiLPRk-",
        "outputId": "a1bb2758-524d-4d47-fd3f-bcf0f6c4cf91"
      },
      "source": [
        "chars = sorted(set(text))\n",
        "print(chars)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '?', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-tnIJEKO8vA"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT15u9lNTGzO"
      },
      "source": [
        "Now we need to transform this script data and character encoding, into the actual datasets that we are going to use for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ-pzG0mTHX4",
        "outputId": "35923d84-dc0c-490f-f06f-a3edf9e110e3"
      },
      "source": [
        "import keras as K\n",
        "\n",
        "seq_length = 50\n",
        "X_train = []\n",
        "y_train = []\n",
        "# X_train needs to be an array of the indicies of the characters in the sequence\n",
        "# y_train needs to be the correct next character\n",
        "for i in range(0, len(text) - seq_length):\n",
        "  X = text[i:i + seq_length]\n",
        "  y = text[i + seq_length]\n",
        "  X_train.append([chars.index(x) for x in X])\n",
        "  y_train.append(chars.index(y))\n",
        "\n",
        "X_train = np.reshape(X_train, (len(X_train), seq_length))\n",
        "# convert to one hot encoding\n",
        "y_train = K.utils.np_utils.to_categorical(y_train)\n",
        "\n",
        "print(X_train[0])\n",
        "print(y_train[0])\n",
        "print(''.join([chars[x] for x in X_train[0]]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22 27 20 37 20 22 39 24 37  1 23 28 20 31 34 26 40 24  0  8  1 39 27 37\n",
            " 24 24 35 28 34  1 23 28 23  1 44 34 40  1 27 24 20 37  1 39 27 20 39 18\n",
            "  1  1]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "character dialogue\n",
            "1 threepio did you hear that?  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcR3qEUZ4Daz"
      },
      "source": [
        "Doing the Training, Validation, Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BleLYZuO4Ike"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# train: 80%, val: 10%, test: 10%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ9QY8lG45Bf"
      },
      "source": [
        "# Task 1 (Part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Lfn0sGWpP2"
      },
      "source": [
        "Now that our dataset is ready, it is time to create the actual model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IorRJJpd5bML"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}