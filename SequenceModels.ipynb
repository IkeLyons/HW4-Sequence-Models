{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SequenceModels.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1OweUI7F-7t3q_iNUKTw-kl71GazFLMXK",
      "authorship_tag": "ABX9TyNM/9xU8d8Ve8LNlaV2pDN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IkeLyons/HW4-Sequence-Models/blob/main/SequenceModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQkC_Q6KLzn_"
      },
      "source": [
        "In this homework I am going to try to generate text based off of the script of Star Wars (dataset link: https://www.kaggle.com/xvivancos/star-wars-movie-scripts). DESCRIBE HERE WHY THIS NEEDS TO BE SOLVED USING SEQUENCE MODELS!!!!!!!!!!!!!!!!! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wAMevRY00TE",
        "outputId": "af38d379-98d2-477b-8777-76370b4194ef"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkuUcgnw5XZj"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjcdXgvz5ZXe"
      },
      "source": [
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMnM1vqv5cme",
        "outputId": "5d6ce416-86f0-445a-e5eb-ea3a3d130ac8"
      },
      "source": [
        "! kaggle datasets download xvivancos/star-wars-movie-scripts"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading star-wars-movie-scripts.zip to /content\n",
            "\r  0% 0.00/158k [00:00<?, ?B/s]\n",
            "\r100% 158k/158k [00:00<00:00, 49.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmP-OVB45nJB",
        "outputId": "654226ef-78bf-458f-942f-e291383f4462"
      },
      "source": [
        "! unzip star-wars-movie-scripts.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  star-wars-movie-scripts.zip\n",
            "  inflating: SW_EpisodeIV.txt        \n",
            "  inflating: SW_EpisodeV.txt         \n",
            "  inflating: SW_EpisodeVI.txt        \n",
            "  inflating: wordcloud_masks/r2d2.png  \n",
            "  inflating: wordcloud_masks/rebel alliance.png  \n",
            "  inflating: wordcloud_masks/vader.png  \n",
            "  inflating: wordcloud_masks/yoda.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cd4zXQ5NP95"
      },
      "source": [
        "We are using TensorFlow and some of the Keras utilties in order to solve this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-hU5EC1NOWR"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGbRUsBINW7Y",
        "outputId": "9392cf32-22ff-46cf-fcbb-70151589d39b"
      },
      "source": [
        "text = open('SW_EpisodeIV.txt', 'rb').read().decode(encoding='utf-8')\n",
        "print(text[:500])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"character\" \"dialogue\"\n",
            "\"1\" \"THREEPIO\" \"Did you hear that?  They've shut down the main reactor.  We'll be destroyed for sure.  This is madness!\"\n",
            "\"2\" \"THREEPIO\" \"We're doomed!\"\n",
            "\"3\" \"THREEPIO\" \"There'll be no escape for the Princess this time.\"\n",
            "\"4\" \"THREEPIO\" \"What's that?\"\n",
            "\"5\" \"THREEPIO\" \"I should have known better than to trust the logic of a half-sized thermocapsulary dehousing assister...\"\n",
            "\"6\" \"LUKE\" \"Hurry up!  Come with me!  What are you waiting for?!  Get in gear!\"\n",
            "\"7\" \"THREEPIO\" \"Artoo! Art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgMEEFTDOPLS"
      },
      "source": [
        "We can see that the script has 3 main parts: the line number, the character speaking, and what the character said. It will be interesting to see how the models are able to recreate this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CixuJiLPRk-",
        "outputId": "adaa6e88-f7ac-47ac-e78a-88c35f9152b0"
      },
      "source": [
        "chars = sorted(set(text))\n",
        "print(chars)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-tnIJEKO8vA"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buz4QGlyQBDQ"
      },
      "source": [
        "The first thing that the model needs is a way to translate from the characters to ids that represent them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVEq5AKROlvA"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(chars), mask_token=None)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXDYOZamQl24"
      },
      "source": [
        "We also need the reverse of the above layer in order to get the human readable text again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbbI10MOQrWP"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDmjiD1VRQD7",
        "outputId": "adc30164-c087-4ebf-f96a-637b5513450d"
      },
      "source": [
        "converted_text = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "converted_text"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(78278,), dtype=int64, numpy=array([ 4, 49, 54, ...,  8,  4,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OhVL2peSdP2"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(converted_text)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT15u9lNTGzO"
      },
      "source": [
        "We are going to need a function that splits a string into what the model sees, and the target text for the model to genenrate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ-pzG0mTHX4",
        "outputId": "0b76e83c-f5f3-401a-a3f0-d93210073b66"
      },
      "source": [
        "def xysplit(text):\n",
        "    X = text[:-1]\n",
        "    y = text[1:]\n",
        "    return X, y\n",
        "\n",
        "print(xysplit(list(\"test_text\")))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['t', 'e', 's', 't', '_', 't', 'e', 'x'], ['e', 's', 't', '_', 't', 'e', 'x', 't'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR_LvAbnTxdO",
        "outputId": "70b468e1-5310-460f-9f2d-760196330483"
      },
      "source": [
        "seq_length = 50\n",
        "seqs = dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "dataset = seqs.map(xysplit)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : [b'\"' b'c' b'h' b'a' b'r' b'a' b'c' b't' b'e' b'r' b'\"' b' ' b'\"' b'd'\n",
            " b'i' b'a' b'l' b'o' b'g' b'u' b'e' b'\"' b'\\n' b'\"' b'1' b'\"' b' ' b'\"'\n",
            " b'T' b'H' b'R' b'E' b'E' b'P' b'I' b'O' b'\"' b' ' b'\"' b'D' b'i' b'd'\n",
            " b' ' b'y' b'o' b'u' b' ' b'h' b'e' b'a']\n",
            "Target: [b'c' b'h' b'a' b'r' b'a' b'c' b't' b'e' b'r' b'\"' b' ' b'\"' b'd' b'i'\n",
            " b'a' b'l' b'o' b'g' b'u' b'e' b'\"' b'\\n' b'\"' b'1' b'\"' b' ' b'\"' b'T'\n",
            " b'H' b'R' b'E' b'E' b'P' b'I' b'O' b'\"' b' ' b'\"' b'D' b'i' b'd' b' '\n",
            " b'y' b'o' b'u' b' ' b'h' b'e' b'a' b'r']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSBxfUmIV3gw"
      },
      "source": [
        "The next step is to split the dataset into batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41PoHYGtVwMk"
      },
      "source": [
        "buffer_size = 10000\n",
        "batch_size = 50\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(buffer_size)\n",
        "    .batch(batch_size, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Lfn0sGWpP2"
      },
      "source": [
        "Now that our dataset is ready, it is time to create the actual model"
      ]
    }
  ]
}